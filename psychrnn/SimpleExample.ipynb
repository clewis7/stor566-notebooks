{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11bb02a-14a1-4e0f-859b-a9d46306be94",
   "metadata": {},
   "source": [
    "# Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e89d76-263a-49c0-8f2e-2928a26814ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6197303a-6ea2-4a7b-9cb9-d268f0fa6ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 13:36:18.627853: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from psychrnn.tasks.perceptual_discrimination import PerceptualDiscrimination\n",
    "from psychrnn.backend.models.basic import Basic\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6624a12a-d5c7-4d69-8550-6859aa1b0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed=2020\n",
    "\n",
    "tf.compat.v2.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4caa28b9-cda8-400f-a353-ff46d31ba5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10 # The simulation timestep.\n",
    "tau = 100 # The intrinsic time constant of neural state decay.\n",
    "T = 2000 # The trial length.\n",
    "N_batch = 50 # The number of trials per training update.\n",
    "N_rec = 50 # The number of recurrent units in the network.\n",
    "name = 'basicModel' #  Unique name used to determine variable scope for internal use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfafc31-c34b-4e7a-850e-1207f8408dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = PerceptualDiscrimination(dt = dt, tau = tau, T = T, N_batch = N_batch) # Initialize the task object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5d0a02-b88b-4f56-a33f-b1851ebe75a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_batch': 50, 'N_in': 2, 'N_out': 2, 'dt': 10, 'tau': 100, 'T': 2000, 'alpha': 0.1, 'N_steps': 200, 'coherence': None, 'direction': None, 'lo': 0.2, 'hi': 1.0}\n"
     ]
    }
   ],
   "source": [
    "network_params = pd.get_task_params()\n",
    "print(network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b3e0c1-be8d-4912-8efb-c783aae84e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params['name'] = name # Unique name used to determine variable scope.\n",
    "network_params['N_rec'] = N_rec # The number of recurrent units in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "200d044f-e149-44bc-8876-4258270d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params['rec_noise'] = 0.0 # Noise into each recurrent unit. Default: 0.0\n",
    "network_params['W_in_train'] = True # Indicates whether W_in is trainable. Default: True\n",
    "network_params['W_rec_train'] = True # Indicates whether W_rec is trainable. Default: True\n",
    "network_params['W_out_train'] = True # Indicates whether W_out is trainable. Default: True\n",
    "network_params['b_rec_train'] = True # Indicates whether b_rec is trainable. Default: True\n",
    "network_params['b_out_train'] = True # Indicates whether b_out is trainable. Default: True\n",
    "network_params['init_state_train'] = True # Indicates whether init_state is trainable. Default: True\n",
    "\n",
    "network_params['transfer_function'] = tf.nn.relu # Transfer function to use for the network. Default: tf.nn.relu.\n",
    "network_params['loss_function'] = \"mean_squared_error\"# String indicating what loss function to use. If not `mean_squared_error` or `binary_cross_entropy`, params[\"loss_function\"] defines the custom loss function. Default: \"mean_squared_error\".\n",
    "\n",
    "network_params['load_weights_path'] = None # When given a path, loads weights from file in that path. Default: None\n",
    "# network_params['initializer'] = # Initializer to use for the network. Default: WeightInitializer (network_params) if network_params includes W_rec or load_weights_path as a key, GaussianSpectralRadius (network_params) otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4438d6-8369-4918-a20c-5d6394acbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params['which_rand_init'] = 'glorot_gauss' # Which random initialization to use for W_in and W_out. Will also be used for W_rec if which_rand_W_rec_init is not passed in. Options: 'const_unif', 'const_gauss', 'glorot_unif', 'glorot_gauss'. Default: 'glorot_gauss'.\n",
    "\n",
    "network_params['which_rand_W_rec_init'] = network_params['which_rand_init'] # 'Which random initialization to use for W_rec. Options: 'const_unif', 'const_gauss', 'glorot_unif', 'glorot_gauss'. Default: which_rand_init.\n",
    "\n",
    "network_params['init_minval'] = -.1 # Used by const_unif_init() as minval if 'const_unif' is passed in for which_rand_init or which_rand_W_rec_init. Default: -.1.\n",
    "\n",
    "network_params['init_maxval'] = .1 # Used by const_unif_init() as maxval if 'const_unif' is passed in for which_rand_init or which_rand_W_rec_init. Default: .1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a32d505-7bb9-4cf9-b632-df4f5aebfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params['L1_in'] = 0 # Parameter for weighting the L1 input weights regularization. Default: 0.\n",
    "\n",
    "network_params['L1_rec'] = 0 # Parameter for weighting the L1 recurrent weights regularization. Default: 0.\n",
    "\n",
    "network_params['L1_out'] = 0 # Parameter for weighting the L1 output weights regularization. Default: 0.\n",
    "\n",
    "network_params['L2_in'] = 0 # Parameter for weighting the L2 input weights regularization. Default: 0.\n",
    "\n",
    "network_params['L2_rec'] = 0 # Parameter for weighting the L2 recurrent weights regularization. Default: 0.\n",
    "\n",
    "network_params['L2_out'] = 0 # Parameter for weighting the L2 output weights regularization. Default: 0.\n",
    "\n",
    "network_params['L2_firing_rate'] = 0 # Parameter for weighting the L2 regularization of the relu thresholded states. Default: 0.\n",
    "\n",
    "network_params['custom_regularization'] = None # Custom regularization function. Default: None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548a36d0-e5a9-4843-bdfa-d4e35a4595ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicModel = Basic(network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53da900e-56d1-4dda-bf7c-4ef8110a97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {}\n",
    "train_params['save_weights_path'] =  None # Where to save the model after training. Default: None\n",
    "train_params['training_iters'] = 100000 # number of iterations to train for Default: 50000\n",
    "train_params['learning_rate'] = .001 # Sets learning rate if use default optimizer Default: .001\n",
    "train_params['loss_epoch'] = 10 # Compute and record loss every 'loss_epoch' epochs. Default: 10\n",
    "train_params['verbosity'] = False # If true, prints information as training progresses. Default: True\n",
    "train_params['save_training_weights_epoch'] = 100 # save training weights every 'save_training_weights_epoch' epochs. Default: 100\n",
    "train_params['training_weights_path'] = None # where to save training weights as training progresses. Default: None\n",
    "train_params['optimizer'] = tf.compat.v1.train.AdamOptimizer(learning_rate=train_params['learning_rate']) # What optimizer to use to compute gradients. Default: tf.train.AdamOptimizer(learning_rate=train_params['learning_rate'])\n",
    "train_params['clip_grads'] = True # If true, clip gradients by norm 1. Default: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "383494bb-cab4-49e7-8266-53e484d15a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['fixed_weights'] = None # Dictionary of weights to fix (not allow to train). Default: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9894e2fd-a661-43b5-bd0b-fb0843a60597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['performance_cutoff'] = None # If performance_measure is not None, training stops as soon as performance_measure surpases the performance_cutoff. Default: None.\n",
    "train_params['performance_measure'] = None # Function to calculate the performance of the network using custom criteria. Default: None.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd80e5db-2e2b-4616-9cf9-f6ced7d2f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 13:40:01.076678: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.076710: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.086375: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.086396: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.088367: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.088375: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.090270: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.090277: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.092166: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.092173: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.094055: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.094063: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.095943: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.095951: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.097813: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.097821: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.099673: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.099680: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.101523: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.101530: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.103388: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.103395: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.105242: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.105250: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.107093: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.107101: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.108932: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.108939: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.110770: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.110779: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.112599: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.112606: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.114424: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.114432: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.116233: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.116240: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.118044: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.118052: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.119850: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.119857: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.121652: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.121660: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.123446: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.123453: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.124373: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.124379: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.125304: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.125311: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.126234: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.126240: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.127157: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.127163: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.128077: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.128083: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.128996: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.129002: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.129922: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.129929: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.130846: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.130852: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.131768: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.131774: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.132691: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.132697: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.133615: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.133621: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.134540: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.134546: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.135463: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.135469: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.136382: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.136389: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.137305: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.137311: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.138231: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.138238: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.139155: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.139161: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.140076: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.140082: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.141000: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.141006: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.141928: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.141935: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.142864: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.142871: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.143794: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.143800: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.144719: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.144726: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.145647: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.145654: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.146573: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.146579: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.147498: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.147504: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.148427: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.148433: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.149367: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.149373: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.150294: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.150300: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.151220: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.151226: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.152152: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.152158: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.153076: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.153082: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.154006: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.154012: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.154928: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.154934: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.155851: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.155857: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.156775: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.156781: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.157703: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.157710: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.158628: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.158634: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.159552: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.159558: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.160476: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.160482: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.161407: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.161413: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.162332: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.162338: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.163256: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.163262: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.164180: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.164185: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.165110: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.165116: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.166041: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.166047: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.166966: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.166972: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.167892: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.167898: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.168822: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.168827: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.169759: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.169765: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.170684: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.170690: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.171608: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.171614: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.172532: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.172538: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.173459: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.173465: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.174383: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.174389: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.175312: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.175318: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.176240: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.176246: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.177168: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.177174: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.178095: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.178101: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.179020: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.179026: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.179943: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.179949: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.180868: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.180874: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.181800: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.181806: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.182731: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.182737: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.183659: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.183665: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.184583: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.184589: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.185517: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.185523: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.186448: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.186455: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.187376: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.187382: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.188300: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.188307: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.189228: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.189234: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.190153: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.190159: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.191081: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.191087: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.192007: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.192013: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.192940: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.192947: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.193874: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.193880: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.194806: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.194812: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.195734: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.195740: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.196658: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.196664: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.197585: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.197591: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.198511: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.198517: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.199438: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.199444: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.200366: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.200372: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.201303: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.201309: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.202234: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.202240: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.203160: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.203166: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.204084: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.204090: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.205008: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.205014: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.205935: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.205942: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.206861: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.206867: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.207786: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.207792: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.208714: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.208720: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.209644: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.209650: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.210568: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.210575: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.211491: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.211498: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.212420: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.212426: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.213347: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.213354: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.214273: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.214279: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.215196: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.215202: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.216120: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.216126: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.217043: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.217049: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.217978: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.217985: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.218909: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.218915: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.219839: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.219845: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.220767: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.220773: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.221698: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.221704: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.222627: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.222633: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.223554: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.223560: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.224478: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.224484: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.225410: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.225416: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.226335: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.226341: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.227259: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.227265: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.228182: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.228188: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.229106: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.229112: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.230039: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.230045: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.230967: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.230972: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.231891: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.231897: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.232815: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.232821: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.233750: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.233757: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.234681: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.234687: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.235610: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.235616: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.236538: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.236544: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.237464: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.237471: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.238390: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.238395: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.239313: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.239319: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.240241: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.240247: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.241172: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.241178: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.242101: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.242107: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.243036: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.243042: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.243969: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.243975: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.244895: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.244901: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.245822: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.245828: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.246748: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.246753: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.247671: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.247677: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.248595: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.248601: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.249526: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.249533: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.250452: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.250458: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.251376: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.251381: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.252303: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.252309: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.253235: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.253241: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.254164: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.254170: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.255093: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.255098: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.256018: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.256024: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.256941: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.256947: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.257867: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.257873: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.258793: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.258799: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.259721: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.259727: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.260648: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.260654: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.261575: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.261581: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.262501: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.262507: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.263425: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.263431: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.264355: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.264361: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.265291: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.265297: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.266222: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.266228: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.267147: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.267153: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.268070: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.268076: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.268993: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.268999: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.269919: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.269926: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.270846: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.270852: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.271775: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.271781: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.272702: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.272708: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.273629: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.273636: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.274564: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.274571: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.275493: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.275499: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.276417: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.276423: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.277349: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.277355: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.278274: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.278280: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.279202: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.279208: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.280130: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.280136: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.281055: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.281061: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.281991: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.281997: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.282919: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.282925: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.283843: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.283849: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.284767: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.284773: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.285696: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.285702: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.286625: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.286631: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.287549: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.287557: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.288476: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.288482: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-11-12 13:40:01.289577: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-11-12 13:40:01.289585: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node '2_9' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2126808/1978373405.py\", line 1, in <cell line: 1>\n      losses, initialTime, trainTime = basicModel.train(pd, train_params)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 461, in train\n      self.build()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 258, in build\n      self.predictions, self.states = self.forward_pass()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 85, in forward_pass\n      state = self.recurrent_timestep(rnn_input, state)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 38, in recurrent_timestep\n      + tf.matmul(\nNode: '2_9'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node 2_9}}]]\n\nOriginal stack trace for '2_9':\n  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n    app.start()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_2126808/1978373405.py\", line 1, in <cell line: 1>\n    losses, initialTime, trainTime = basicModel.train(pd, train_params)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 461, in train\n    self.build()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 258, in build\n    self.predictions, self.states = self.forward_pass()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 85, in forward_pass\n    state = self.recurrent_timestep(rnn_input, state)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 38, in recurrent_timestep\n    + tf.matmul(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\", line 3714, in matmul\n    return gen_math_ops.mat_mul(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6034, in mat_mul\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3800, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node 2_9}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses, initialTime, trainTime \u001b[38;5;241m=\u001b[39m \u001b[43mbasicModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py:553\u001b[0m, in \u001b[0;36mRNN.train\u001b[0;34m(self, trial_batch_generator, train_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m epoch \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m<\u001b[39m training_iters \u001b[38;5;129;01mand\u001b[39;00m (performance_cutoff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m performance \u001b[38;5;241m<\u001b[39m performance_cutoff):\n\u001b[1;32m    552\u001b[0m     batch_x, batch_y, output_mask, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(trial_batch_generator)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_mask\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mask\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;66;03m# Output batch loss\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m loss_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/client/session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1393\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1396\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node '2_9' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2126808/1978373405.py\", line 1, in <cell line: 1>\n      losses, initialTime, trainTime = basicModel.train(pd, train_params)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 461, in train\n      self.build()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 258, in build\n      self.predictions, self.states = self.forward_pass()\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 85, in forward_pass\n      state = self.recurrent_timestep(rnn_input, state)\n    File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 38, in recurrent_timestep\n      + tf.matmul(\nNode: '2_9'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node 2_9}}]]\n\nOriginal stack trace for '2_9':\n  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n    app.start()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_2126808/1978373405.py\", line 1, in <cell line: 1>\n    losses, initialTime, trainTime = basicModel.train(pd, train_params)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 461, in train\n    self.build()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/rnn.py\", line 258, in build\n    self.predictions, self.states = self.forward_pass()\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 85, in forward_pass\n    state = self.recurrent_timestep(rnn_input, state)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/psychrnn/backend/models/basic.py\", line 38, in recurrent_timestep\n    + tf.matmul(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\", line 3714, in matmul\n    return gen_math_ops.mat_mul(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6034, in mat_mul\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/clewis7/venvs/stor566/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3800, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "losses, initialTime, trainTime = basicModel.train(pd, train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee110e-60bd-465e-bb22-4863cb1af189",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Iteration\")\n",
    "plt.title(\"Loss During Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
